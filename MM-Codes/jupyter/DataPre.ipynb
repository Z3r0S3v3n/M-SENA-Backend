{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as plk\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch import autograd\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 寻找合适的片段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dir = '/home/sharing/disk2/multimodal-sentiment-dataset/MSA-ZH/label/sentiment'\n",
    "df_t = pd.read_csv(os.path.join(label_dir, 'label_T.csv'))\n",
    "df_a = pd.read_csv(os.path.join(label_dir, 'label_A.csv'))\n",
    "df_v = pd.read_csv(os.path.join(label_dir, 'label_V.csv'))\n",
    "df_m = pd.read_csv(os.path.join(label_dir, 'label_M.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_v, neg_v = 0.6, -0.6\n",
    "t_pos = df_t[df_t['label'] >= pos_v].index.to_list()\n",
    "t_neg = df_t[df_t['label'] <= neg_v].index.to_list()\n",
    "a_pos = df_a[df_a['label'] >= pos_v].index.to_list()\n",
    "a_neg = df_a[df_a['label'] <= neg_v].index.to_list()\n",
    "v_pos = df_v[df_v['label'] >= pos_v].index.to_list()\n",
    "v_neg = df_v[df_v['label'] <= neg_v].index.to_list()\n",
    "m_pos = df_m[df_m['label'] >= pos_v].index.to_list()\n",
    "m_neg = df_m[df_m['label'] <= neg_v].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listUnion(a, b):\n",
    "    c = [v for v in a if v in b]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2117\n",
    "print(df_t.iloc[index][['video_id', 'clip_id']])\n",
    "print(df_t.iloc[index]['label'], df_a.iloc[index]['label'], df_v.iloc[index]['label'], df_m.iloc[index]['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 绘制音频波形图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iyuge2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAdVUlEQVR4nO3dd7gsRZkG8He4IFHCrgpIKhAFUZEooqASxFCGFREDsq6yioo5QBl2QZbFQsW4gmHN6KIsgkLJopJEccWrIFkJFkhc4CISBATO/lHd9/Tp02l6uqs6vL/nuc/M6e7prjsz/U11ddVXk7m5ORARkR8rhC4AEdGYMOgSEXnEoEtE5BGDLhGRRwy6REQeMegSEXnEoEtE5BGDLhGRRwy6REQeMegSEXnEoEtE5BGDLhGRRwy6REQeMegSEXnEoDsSQpnnCGW2CF0OorFbMXQByJuzosdJ0FIQjRxrukREHjHoEhF5xKBLROQRgy4RkUcMukREHjHoEhF5xKA7MkKZjwhlzg1dDqKxYj/d8fnX0AUgGjPWdEdKKMNBEkQBMOiO1ztDF4BojBh0x2vP0AUgGiMGXSIijxh0iYg8YtAdL95IIwqAQZeIyCMGXSIijxh0x4vNC0QBMOgSEXnEoEtE5BGD7ogJZV4ilNkmdDmIxoQJb8ZrAuAHiedE5AFruuPF6diJAmDQHa9N4ydCmVWEMhuFLExoQplnCWU2DF0OGj4GXQKAkwBcF7oQgZ0D4PLQhaDhY9AlAHh+6AJ0xBqhC0DDxxtpAyeUeQWA1UOXg4gcBt3h+17oAhDRPDYvEBF5xKA7YJwHrTlCmXWEMo8MXQ7qPzYvDNuzp9lYKPMoAKcC2NdqOfbeDGnLANwNgIGXZsKa7rCtPOX2+wPYCcB7WijLELB3A82MQZeS5qJHNksQtYRBl5LmyjcZN7aT06wYdIetbhBlYMm3afkmRPkYdCmJzQvleDVAM2HQpSQGXaKWMehSEoNuOb43NBMGXSIijxh0KQtrc/nYpksz4Yg0oulMom5jRwP4otXy94HLQz3Dmm4GoczjhDKrhi4HddbmAN4N4JTQBaH+YdBNEcosAXAVxpkS8RGhC9AVQpmDhTK/KNmMzTA0NTYvLBb/EL0gaCnCODp6ZDABjspZzjZdmglruostP6mEMh8WylwasjDUORPwR4lmwJpuvgmAfwtdiDqEMiuCTQVEncSa7mKT1GMfnQTgHvDzbQubGKg2npSL9TnYxl4UPZ4QtBQtEspsIJRZN3Q5iKbF5oV8Qwi+Q066fX30OPXnJJRZH8ASq+X1pRtni4+5Us3X04gx6C42hGBLxW6MHmf9rDeZtSA0PmxeoExCmTcKZfYOXY4OmoBtujQDBt3FWNN1vgTgxNCFCE0os1boMtCwsHmBsvCHZ96hWDhR5xxS749QZhUAewI43Wr5N49lox5iTXcxBhxKWlJhmwvg8jB8vOWy0AAw6BIVS/8IZ7Xpbhk97th+cajvGHQjQpn1hDKHIuM9EcqM9n0SyqwllNk2dDk6Ju9qiFdJVGq0wSTDNwEcBuDpGes+5bcowSWDx2kAfhuqIDGhzOFCmbloiHNyedvf4XStlj0XaCYMuvNWix6zbi6+3mdBOmZnYD64CWVOF8ocE6Ac740eV0ktf1bLx81qXiCqbXBBVyizklCmzkihuAYzuPekIfH7sheAtwQ4fl4Ns3YQFMps35Wy0HgMscvYvQBuA7A+AERTq2gAX7ZaXlXwuoejx6ygO+aT6WG492QJgAcDlyVL4WcjlNkdwIZWy29mrF6vjWMSFRlirW5FLDyZNgdwMIAflryONd1sRT9GfXAGgG/krGs6eDIYU6m+nkjTiINpWX7ZoqA7tpPpTYnncdCt0l/Vh/Rn0aUbW2P7nlANYwi6VWtq8cnLE2ehrtR08z6fEJ9XlwI99cwQ23TTCoOGUGZTuJ4LXQkuXdOVmm6XAh376VJtXoOuUGbzkptZdfc7AfAJAN/JWB2frHlp+K6JHn8aPT6+waINQdfaun03L0yi7xdRI7ydSEIZCeBKocwrGt7v1nDDL98D4NyMTR6quKv45NVNlGtAulLTjf1dgGN+uOJ2DM5UymftZevocbuG9/s7AL+Knj+cXBHVUOIT4ZaS/XTp8rVLutLsEn8+Z6WWfyx+IpR5p1Bm5yn2WTVI7jvFPokKtd68IJTZDAunjWmsNhBNu5KUnD59PwDHAdii4u6Kgu6YazDxQJOuvAebpD73HRLPPx095pZVKPPSGsdMfjeK3oeuvEfUYT5qL1fD1UbbcGPq7+QlcJxm71EV9/VwwbqJUGZDocw/VC3YgMTDoydCmVUDlmPNxPP0514qMUrx5JLtsppRqgZTBl0qFaL3QpuX8cmgkL4BVHbcspruLwBsjPGeWBOk8sVGyWdeB+DrVsuqbeetEMq8u2ST/QF8tcKudhPKJJuipvm8N59iWxopn0F3+ZdXKLMagAeslrWHlQpltqm4adXafFnQ3Tg67sRqOdb233QPkHiWhCVw0/uE9MmS9StnLMsKqBO4WSCS5nKep60ZtSm/EMBhoX+IqJtaCbpRDegUAB/JWD0H4BwA9wPYZcr9rgJgVavlHXDZ+ovEJ8fy/6NQ5s0A9rJaZk24+PyKxRjrxIQTAC/KWVe1CSek3B9focxWqUX/nnie/qwnmM94luUEABsA+GdE+T+Iktqq6W4KF8TyLrd2yFle5hcAthPKVJkwMT5Zkm10xxZsX9QlapLzfEyKMreF7tlQRdHndknq72QzVfp1K2LhMOm0+LV1k+nQwLV1ssTNBsmg3kSwirubvbzCtllBt65k3oY+BJg2FPWv7sMPUdVeB2X/l7K246IbskStBZC4LSsr6Fa+NI9mCshKyVdFunlhUc2j5qwDj5v2BUKZ84QybfXg8OWo0AWYUVM/DH9fsn6MTU80hbaD7oYZ66b9Uu5fswwbR4+7F2zznBr7/d8ar9kZ84NDWiWUebKP46T0oaZb97t+ELK/x3lY06VCbQXdvLvCtQllNi7fKlPm5WA0a8AaWetKrCWUeUzNssxEKLOPUKZsdFTWzUua7Tu5TuJ5yL7KNABt3UiLg/mdANZKrcus6QplDgLwWgC7wg3t/Fhqk8bKKpTZEMBSADfX3MVNCJOL4ITo8XsF23i5vBXKPNXHcarIS0iTWt5UbXzt1DGenVrfh1o/BdR2TXea2sV/wM3Euztc7XR5v0+hzI5wI9uaEt+Qq3uHudb7JpRZKpTJ6q7WJF9tilsmnk8AF4CEMqWTeApljhfKFPUASG9/SMkmf8lZ/srE87a+62en/mbQpUJt13SzahrJ/AhrADgRwFsT28U9H56XWLZgJFQDpr4ZVkQo82IAp6UHewhlnoaFfT63h0s/mZ7Rto+ygvvZ0ePXSl77yuhf6YCKKM9CWea3Rc1EQpmnoPxHtU6AfEYL+6QR8Rl0s7wAbnbZ5En1QPSY7KaVvoSb1ZFN7ShqY/0u3I9Fui/r6UhdjqJmTbTjOV3bLNvPpn2BUGY3AGcC+H1isa/3b7XyTWjM2rrkqlTTBfDijO18aKSmGTUVxElwsn7AsgJscjj0IUKZfSoe7glTFq9tuX2lhTLr5K2roU4+gzgRfTLDXPoeAQBAKHNgatEeNY6XtCDoCmV2nTLdJA1ciOaFpP0L1nVaNNS5bGRcZtAVyuwKl3ktruFX+f9X/ax8vZfJXhQToUzyR2GZx3Jkyey2lXG1cFLGZltmLJtFXFPv3Xec2tH2jbTkr358rLKbIn0Z8ZXZLiyU2U0oE7fjZp1oj4A7EYt6IJQSyuwglLlGKJPuHRLC9gB+nVwglHl11RcLZbZKpF5sQl4TTlbSm7SXNFWIZA1XKLOZUGb1pvZN/dV280LWsqyp0JN39LsyLUyZvGljzgTwwegmWtFldtUsaXkOh8txkU4aFKJGJbEw3y1QcdqjqPvepQAeEMoc2VDO3v/MWf7tBvY9jWQ5rgZwnufjUwf5DLpVewz0ZYbishPoVyXrm+ralZUFqws2rhhAN0s8/wCAe1sqD7Dwx92HTVN/exmVSN3mM+i+quJr0zWm3hDKHDbF5smucxOhzDtKRrptlrM8PUghfaKHtJ9Q5lKhzBFCmXQvjtiinilCmappNol6x2fQreq/GyuFf4dOsW2yhrofgM8A+FbB9gek/n5i9HikUCZ5FTFrs0WTvgxgKwAfQv7ov6wa/2lCmcd1vJtcFRwyTIv4zL1ACyWDTdyLY6uMhNqx9HsqEs/LMl91waKbWFHNPi+R/VUAfthqiQKJrmzmhDKZ3dho2LpY0x2L5A3F+OZhfFOpFqFM1k3KLrsFC0cepuXNVNFbQpn3Y75Xz/vjHg1CmV2EMpdEU1k1ebyJUOZYoczuiWV7CmVeGz1/S/QDkM4psYNQpm6GPyowmZtrfqh+lCvh/MZ3PCx3Y3746uWYby6A1XLRlYJQJvlBfRbAOxJ/HwzgeACHAXhD0wVt0CFwowH70kOlLXOYv3J5EoArANwG19vl6VbLspuwlUQ9QyYArstab7WcCGWWYb6XzQoAdoKb+25ptOxlVsuThTLXwfW/fiqAt8A1HT0PgAGwhdXyDxnH/y7cQKR94abJOqWJ/1fftRV0d0K9vLNj8iAKemqkA28q6Ga5D8PI6TA252FhPoeXA5izWmYN3CgU5ZvYwGr5P9HfTZ3cR6G4f/174PJoHALX1PU2AI+EyzIIAL+FSzL1TAB3weWXvgbATwB83mr5tvQOhTLPAvBhuORX18O9RxdZLW+I1j8CgALwcavlX2f8/3nVVtDdGeyTOKt4sMA+AC6Eqw3TyES10e0B/BGuBnp33mzUiSC7N1wf4by+5F3zObgroK/ABeJlAL6Rs20cwJMOA/Abq+WpbRWwSW0F3WfATSJJRLPZF4tHL54P4KvRv9cA+LrnMnXZJwA8Fm628J8CuBiu1r0ygE0A3GO1vDQaxr+W1fJ23wVsK+juAuDcxndMRNSuAwH8Eq6N/R6rZV6u5trYe4GIaN4XAVwE4EYAH2zjAG1nGSMi6pvL4HoIXdjGzhl0ifrtSsznD6aFDgJwCtwNujm43BcHwPUPPxLA0XCDjH4ONzP4sXk3KZvUVtDNG2VE1W0HNyJrmum/aZgOB3AEgLWtlremV0ZJ458K4CzfBWvBjnBdzT6H4oEzWQSAxwC42Gp5X2L5Xhnbpvd92ZTHqq2toLt+S/sdk4fgfryehmq5d7cC8GMwSPdZ3Hd7f7gg+3i43gn/ZbX8G4BFARcArJZ3wM1PF08QuhfcoIU2M/YtGNCT8GsAf8LCjG73Yn4U3mpwPQn2h7uEB9wozCfB9SaIb1w9XyjzKQDvAvC+aNk1ACxctzHAzR7+Q7iJSY+zWl4L4NqZ/lcetNV74QDk5zSlah5ttbwNyOz3/CYsnNTxR1ZLKZR5Llzgpf75HIDD4898VlHf3iOxsJZ3KdwchNtGfy8FsEPOLr4Cdyl+uNXy0IyBFuvB3eH/F7iJZZcAeKbV8oro+KvDjboE3P/t7QDeZbX8TLR+AuC9AI6FG9izdtXuW0KZjeAC9CXR32vD9V9+sPiV3dBW0J0gZ8oUKjUHYCWr5UPJhUKZ/QAcF/25Lly7VCwOunvCdS7vohsAbJBadjv6kazHh7Xa6J4klFnBavlw4u93A/gkgJOslntH/VX/Fq3+RwDfBPBSuMvtiwFsbbW8MsrV8CBcTfblVsvSZD1CmT3garCXwX0vt7da/rb4VcPXStAFKg1BXIb+jJhp0x+RyoGbk3vhNZif+WAduEu4OHfDW62Wx3Y86F4I4Ay4MseTQS6Ba0bJ82m4y8uhWhXu0nsCV9O7s2T7mUUVorWjJol42VoAJlbLP7d9fArby4A1Yee1cDdByiZETL5fdwK4P3q+BYAvtFCupsS1qAetlu+zWr45XhHVwIrmLZtpHrmO+250syeu3XpJh2q1nEsG3GjZnQy4/rBrVzgXR48PWC0vgkvqUWR50I26tcQn6TIf3VzqiGrs8cwQmTVaq+UDWTX7gXs05nMox58rz8WRaPODfmni+REZ6x9V8NoHGi6LL4eXrL8mY1lcE7w/Y13S0pzlnQy4mM9KFaf8+2TF1z0PLnvUVhhoMnyr5W1RbwRgfhblXtwEotm1FnStlsms/8umfPkJTZbFF6vloSW1tlsyls1Fr41PupNzXvvH1N+nR4/3pTcMaAUA50TPrwUAq+XtVsuJ1bJSU4HV8sdWy6OslrNkVXs8gM0B3JRafvwM+5zFmnC9CO7KWLcP3F3/xm+iUTf5uqSZtjY21F/9rMklk0F6PQCvzHphRhPC6wFsbrW8p6GyTWtRG2BUxv8LUJZ0Oa6yWl4N4MTE4oetlq8OVJ67rJY/get1skbGOqZBHRFf051Pe9PsYACva6Mgga0bPf4Z88E22VabVRPOZLW8H8DVzRVtalcAeHrG8vjHoQtNAwouoXYn9C3ZNrWjkzVdq2WbtaVjWtx32pcK1sWXvn09EW/IWb7ox2QGM7VXB7wKIMrlK+h2qXuYjyB3JgBYLQ/MWT+BG975T1bLqzyUpw3JgPhcuIQhwPx3qqs3+MocNeX2i+YGIyoSsnnhHLjuRBYLpxNvWxPB4FS4nJvnR/9uTK3fs+T1k2i4Z96UJHX5vKRPvo8XJIZwxkF32h/aM9Bue3DWe7MxXPet3ySWfRTF84GlbYluVSqo43wF3axA92oAL4Mbe+3zS9tE0L3Havmh+A+hzIKVFfrNDq1PZvL/W6t5wWqZ9UOVdbc/banVcscKIyCzgu59cD/6tVkt59Kff8o5RStpfEK26d5stTwmFaCegMWTzvkoy6z72A/ZN5XydOEmU5OS70c8lLWoGadSYpMoocmnSjab9WZik+2+p6X+Xg3lVz00MsFqulm1QavllX6K0yyr5XdClyGAuZzn74QbbXc68m2I6j88x8NNwx37OYrzNduK+wXcVOf3l9RUp3EWgBcsLwh7K1CGkM0LZdrKQNXEaLdp/j/3wY06uxLztfi6Vxi7IaN/bEJmvlUPlr8fUdKWo4s2TiWYLvNruFld4xrjeQC2h0sWQ9Q7XWlb/ASAF6aWCbQXdPeBSxTTOqvlqlbLNa2W2ycW13rfrZZnWy1z522K1j07b33D8mq6jYquiD6fOlbR8fLWZQ3Bnub1VQyt2Yha0ImartXy/RnL7gYW36RqwE1WyxNn3PesQaa1k9Nq+bMW3rMsXoJuJP1+Fd2kyxvNuH/Gsjrl/iBccnCiWnzVdJPHmTYPQ1pep/wyuwJ4A4Cvznj8JgytRuSzT+4c6gXdurlqL0r9fS2AN+Zsm/xcT615PBo4XzXdZNDdDsA2M+yrVvcyq+XP4W7CNKFukLkZLr9CL28Ypvis6a40xbGa7n74cQDfqrjt0H5MqQXea7pWy2utlj+YYV8bNVCetNKpR1LqBpm4hhQk8UrDku9B2/2sk70V0jXd9GeRV5Y4ICavdLI+xzm4H8aibYhq8xV0l3g6TqdZLU8FsEKUtHxI2g5M6UCaNRgjVjT9D6yWB2Qs3jbx/L5U4qE5uG5wecdPmlTYhkbOV9Dten6BqpeFM2c+6+osDzPyGXTLarZ1at3Lp69JJBdHYtlnE38mZ+1IY/MClWo76MY5CS4u3Cq8qidLvN0QA+e0fN88y/u7avNCU6p+V/gdoUxtB934TvKKAL6GxGidKdjGSpNv2hOEJ5TfG2nJYcNl/XSnCbpVyp3X7puFNV0q1XbvheVB12r5hpr7eArcGPbKCb5rmLamO0bHAHgGsnuetB10k5N2poPuHalt8zKENfXZFTUvEJXyVdOtfSPNanl3y0nNp3EaXPAvHOY6RFbLg7Cw18WfEs991vwvTB0vDrJ3J9a3ic0LNJO2a7rxnWRf/YGz3IP5EzJPpRMpuqu9XumG43AYgA9Ez70FGKvl94UyX0j8HWcJq1OGuuVm8wLV1nZN94LoMdS0KUcDWBsuq1WR9CUqFfuD1TKZOKhLw4DbLkvV/bOmS5naroG+EcCXrJa25ePkuTkxtXkRBt1qQgeSe1va77Q11CpdxirlDKbxaTXoWi3vRdjM+U38/86Ea5NeuYF99V2cOvL41HJfwTieUr1OljEfl/7JY7zLw/Goh0K2tfrQRG1jBavlcxrYT+9ZLZcJZR6JVI0zwICPouPVCa5Ndhn8E4CN4ix5RGl9Crq3wk0ieAXcZIBFDoBLHp6ukVE9Z8dPAgeTudRj1rpp1K39FjUvbAPgMTX3SyPQp6B7PVzQLb0pZ7WcNn1jncvVMbgEwJNDFyKhrRGBjTU9WC2XYfb0pTRgXZk5oopJ6tH3ccfosOjx5pCFyOCzVpt2WsHxx/xdoYr6FHTj6bh9TtcOjPtE+hWA1wM4MHRBIkXNC7FZ2nRLB+FYLYvmqBvzd4Uq6lPzwqvgsnw9AcAODe1zR5TPKTbmE2nOavn10IVIKGpeaKLJYZoJMwHg26m/x/xdoYp6U9O1Wt5otfwoGmzPs1outVoe3eQ+B6asX+wsyehncWPBurzAVzQLdN1geX/qb36PqFRvgm5CG7WJuP9p1knT59qLnenFWpYNGtkX7uamL/Hn86ppX2i1vHyK/RO1pk/NC22KR62dAuAlqXV9DrqXw01l34poKPBtbe0/Ia5Rxj1Xbs3bcErpz5bZ5qh1fazp+r6RRuGdAOBQ5KdtBOb7ZE/bLtuk4wIem3qijzXdpXBTqZ8BYA+4WlCbQ3T7XKsZxOWy1fIhAIcnFmX9v94G4ENWy7/OcKiZktlYLYcwyzO1rI9BN67pFt1MaVKfg26fy15kUdCLEhsxyQx1Xh+bF9InXFuBJT7OuS3tv007Adg6dCF6KOu79EvvpaBB62PQbUM828C3EsvOjB7P8FyWmVktz7dazjIZqEG3mybisi2aubdpAdOS0kD1sXmh8Zqu1fLaeD9CmbzjjMkHrJYvCl2IAMb8mZMnfa7pxidI2/+HPreLDjWIxP+vWT+bpj7bGxraD41AH2u6RE2bNfhuCWCVJgpCw9fHoOvrRhpRJVGOYSYtp0r63LzQtqFemg9B05/NtPvjDz3V1segG/fFvCl6bPsE4AlGRI3pY9A9GcD+AD4S/d12P90x6voPTTxA5szCrcrFCX2m/f+O+btBM+pd0LVazlktj0Nxqr4mdT0AjU40LPiJAPaecT/M40He9fFGWqzt2kZT3ZL6KJ0ntnOsllc0uLtpv0tLo8cfNVgGGone1XQTfAXd0bFa/j50GRq0LYAnNblDq+XvAKxqtTyxyf3SOPS5ptumv2A+AfidAcvh21IA3w9diCZZLS8s36rWfkOmkKQe623QtVrOJYbsNml1zNdyf2K1PK+Ng3SR1XLH0GXw5MUAbslYPsamJPKst0E3x3YAdp5lB1bL5Lxgg6r1kWO1PDW1aLRNSeTfoIKu1fICABeELgcNwmMBrBS6EDQ8gwq6RDNa3rxgtbypaEOiuvrce4GoKWxeIG8YdImIPBpC0L0qdAF67t7yTYioKX0PunsA2AXAFQDOCVyWvrKhC9Ah7DJGrev1jTSrZZzw5IlBC9JdbKushu8TedProEulqtTc5gCsD+DBlsvSZXdFj6cFLQWNAoMuwWp5c+gyhGS1/LNQZhPM52gmag2DLhEAq+V1octA49D3G2k0O7ZnVndt6AJQ/7GmSwy61TwFbH6gBjDoDtutoQswFFbLS0KXgYaBzQvD9vbo8QsF27CmS+QRg+6AWS3vslpOwKBL1BkMuuN1ROgCEI0Rg+543R66AERjxKBLbF4g8ohBd7wYbIkCYNAdr7nUIxF5wKBLROQRg+54saZLFACD7jjclrGMwZYoAAbdEbBa3hC6DETkMOgSa7xEHjHojtcd0eNlQUtBNDLMMjZefwCwJ4Bfhi4I0Zgw6I7XnNXyjNCFIBobNi+MF9tyiQJg0B0vBl2iABh0x+vC0AUgGiO26Y7PTgD+YrV8OHRBiMaIQXdkrJbnhy4D0ZixeYGIyCMGXSIijxh0iYg8YtAlIvKIQZeIyCMGXSIijxh0iYg8Yj/d8dgTwLqhC0E0dpO5OQ7BJyLyhc0LREQeMegSEXnEoEtE5BGDLhGRRwy6REQeMegSEXnEoEtE5BGDLhGRRwy6REQeMegSEXnEoEtE5BGDLhGRRwy6REQeMegSEXnEoEtE5NH/A4K9xLCh9HYaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wave\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "# 打开WAV文档\n",
    "f = wave.open(r\"/home/sharing/disk3/dataset/multimodal-sentiment-dataset/CMU_MOSI/Raw/Audio/WAV_16000/Segmented/8OtFthrtaJM_21.wav\", \"rb\")\n",
    "# 读取格式信息\n",
    "# (nchannels, sampwidth, framerate, nframes, comptype, compname)\n",
    "params = f.getparams()\n",
    "nchannels, sampwidth, framerate, nframes = params[:4]\n",
    "# 读取波形数据\n",
    "str_data = f.readframes(nframes)\n",
    "f.close()\n",
    "#将波形数据转换为数组\n",
    "wave_data = np.fromstring(str_data, dtype=np.short)\n",
    "wave_data.shape = -1, 2\n",
    "wave_data = wave_data.T\n",
    "time = np.arange(0, nframes) * (1.0 / framerate)\n",
    "# 绘制波形\n",
    "# pl.subplot(211) \n",
    "pl.plot(time, wave_data[0])\n",
    "pl.axis('off')\n",
    "# pl.subplot(212) \n",
    "# pl.plot(time, wave_data[1], c=\"g\")\n",
    "# pl.xlabel(\"time (seconds)\")\n",
    "pl.savefig('./wave.pdf', dpi=600, format='pdf')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = wave_data[0]\n",
    "a = a.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.mean(a, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制波形\n",
    "# pl.subplot(211) \n",
    "pl.plot([i for i in range(len(a))], a)\n",
    "pl.axis('off')\n",
    "# pl.subplot(212) \n",
    "# pl.plot(time, wave_data[1], c=\"g\")\n",
    "# pl.xlabel(\"time (seconds)\")\n",
    "pl.savefig('./wave.svg', dpi=600, format='pdf')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [1,12,123,1234,12345]\n",
    "data_dir = '/home/iyuge2/Project/MSA-ZH/results/msazh'\n",
    "models = ['lf_dnn', 'lmf', 'mfn', 'mlf_dnn', 'mult', 'tfn']\n",
    "criterions = ['MAE', 'Corr', 'Mult_acc_2', 'Mult_acc_3', 'F1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for model in models:\n",
    "    model_res = {}\n",
    "    for seed in seeds:\n",
    "        path = os.path.join(data_dir, str(seed), model+'-msazh-M.csv')\n",
    "        df = pd.read_csv(path, index_col=0)\n",
    "        for index in df.index:\n",
    "            if seed == seeds[0]:\n",
    "                model_res[index] = [df.loc[index, 'M']]\n",
    "            else:\n",
    "                model_res[index].append(df.loc[index, 'M'])\n",
    "    results[model] = model_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for modality in ['M', 'T', 'A', 'V']:\n",
    "    model_res = {}\n",
    "    for seed in seeds:\n",
    "        path = os.path.join(data_dir, str(seed), 'mlf_dnn-msazh-MTAV.csv')\n",
    "        df = pd.read_csv(path, index_col=0)\n",
    "        for index in df.index:\n",
    "            if seed == seeds[0]:\n",
    "                model_res[index] = [df.loc[index, modality]]\n",
    "            else:\n",
    "                model_res[index].append(df.loc[index, modality])\n",
    "    results['mlf_dnn'+'-'+modality] = model_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=criterions)\n",
    "for model in results.keys():\n",
    "    cols = []\n",
    "    for criterion in criterions:\n",
    "        values = results[model][criterion]\n",
    "        mean, std = round(np.mean(values)*100,2), round(np.std(values)*100,2)\n",
    "        cols.append(str(mean)+'/'+str(std))\n",
    "    df.loc[model] = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(data_dir, 'stat.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dir = '/home/sharing/disk2/multimodal-sentiment-dataset/MSA-ZH/label'\n",
    "label_name = ['多模态', '视频', '文本', '音频']\n",
    "labelers = ['孟繁阳', '朱益林', '马奕潇', '余文梦']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 去除video_id与clip_id重复的行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lname in label_name:\n",
    "    for i, labeler in enumerate(labelers):\n",
    "        cur_path = os.path.join(label_dir, labeler, lname+'.xlsx')\n",
    "        df_src = pd.read_excel(cur_path)\n",
    "        df_src = df_src.drop_duplicates(subset=['video_id', 'clip_id'], keep='first', inplace=False)\n",
    "        df_src.to_csv(cur_path.replace('.xlsx', '.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 依据标准表筛出无效片段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_standard = pd.read_csv(os.path.join(label_dir, '余文梦', '多模态.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_index = label_standard[label_standard['label'] == 2].index\n",
    "for lname in label_name:\n",
    "    for i, labeler in enumerate(labelers):\n",
    "        cur_path = os.path.join(label_dir, labeler, lname+'.csv')\n",
    "        df_src = pd.read_csv(cur_path)\n",
    "        try:\n",
    "            df_dst = df_src.drop(drop_index)\n",
    "            df_dst.to_csv(cur_path, index=None)\n",
    "        except:\n",
    "            print(cur_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_standard = pd.read_csv(os.path.join(label_dir, '余文梦', '多模态.csv'))\n",
    "video_dir = '/home/sharing/disk2/multimodal-sentiment-dataset/MSA-ZH/raw/v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in video_pathes:\n",
    "    clip_id = path.split('/')[-1].split('.')[0]\n",
    "    new_path = path.replace(clip_id+'.mp4', '%04d.mp4' % int(clip_id))\n",
    "    os.rename(path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(label_standard)):\n",
    "    video_id, clip_id = label_standard.loc[i]['video_id'], label_standard.loc[i]['clip_id']\n",
    "    src_path = os.path.join(video_dir, video_id, '%04d.mp4' %(clip_id))\n",
    "    dst_path = src_path.replace('v-filtered', 'v1')\n",
    "    if not os.path.exists(os.path.dirname(dst_path)):\n",
    "        os.makedirs(os.path.dirname(dst_path))\n",
    "    shutil.move(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 生成各个模态的标注结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['video_id', 'clip_id'] + ['label_%d' %(i+1) for i in range(len(labelers))] + ['label']\n",
    "for lname in label_name:\n",
    "    if lname == '文本':\n",
    "        column_names.append('text')\n",
    "    df_dst = pd.DataFrame(columns=column_names)\n",
    "    labels = []\n",
    "    for i, labeler in enumerate(labelers):\n",
    "        df_src = pd.read_csv(os.path.join(label_dir, labeler, lname+'.csv'))\n",
    "        if i == 0:\n",
    "            df_dst[['video_id', 'clip_id']] = df_src[['video_id', 'clip_id']]\n",
    "            if lname == '文本':\n",
    "                df_dst['text'] = df_src['text']\n",
    "        df_dst['label_%d' %(i+1)] = df_src['label']\n",
    "        labels.append(np.array(df_src['label']))\n",
    "    df_dst['label'] = np.mean(np.array(labels), axis=0)\n",
    "    df_dst.to_csv(os.path.join(label_dir, lname+'.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 绘制标注结果统计图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font',family='Times New Roman',size='13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = []\n",
    "label_dir = '/home/sharing/disk2/multimodal-sentiment-dataset/MSA-ZH/label/sentiment'\n",
    "annotations = ['Negative','Weakly Negative','Neutral','Weakly Positive', 'Positive']\n",
    "for lname in ['label_M', 'label_T', 'label_A', 'label_V']:\n",
    "    df = pd.read_csv(os.path.join(label_dir, lname+'.csv'))\n",
    "    counts = df['annotations'].value_counts()\n",
    "    label_counts.append(list(counts[annotations]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =np.arange(len(label_counts[0]))\n",
    "bar_width = 0.2\n",
    "fc_M = [1/255,77/255,103/255]\n",
    "fc_T = [96/255,143/255,159/255]\n",
    "fc_A = [251/255,178/255,23/255]\n",
    "fc_V = [237/255,222/255,139/255]\n",
    "plt.bar(x, label_counts[0], width=bar_width, label='M',fc = fc_M)\n",
    "plt.bar(x+bar_width, label_counts[1], width=bar_width, label='T',fc = fc_T)\n",
    "plt.bar(x+bar_width*2, label_counts[2], width=bar_width, label='A',fc = fc_A)\n",
    "plt.bar(x+bar_width*3, label_counts[3], width=bar_width, label='V',fc = fc_V)\n",
    "\n",
    "plt.legend() # 设置图例\n",
    "plt.xticks(x+bar_width/2,annotations, rotation=15)#显示x坐标轴的标签,即tick_label,调整位置，使其落在两个直方图中间位置\n",
    "plt.savefig('./asserts/dataset-bar.pdf', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 计算各模态之间的标签差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = []\n",
    "for lname in ['label_M', 'label_T', 'label_A', 'label_V']:\n",
    "    df = pd.read_csv(os.path.join(label_dir, lname+'.csv'))\n",
    "    ys.append(np.array(df['label']))\n",
    "ys = np.array(ys)\n",
    "# diff = 1- np.corrcoef(ys)[:4, :4]\n",
    "diff = np.zeros([4,4])\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        diff[i][j] = ((ys[i] - ys[j]) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.YlOrBr):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    YlOrBr\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(4),\n",
    "           yticks=np.arange(4),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes)\n",
    "#            title=title)\n",
    "    \n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    \n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=0,\n",
    "             rotation_mode=\"anchor\")\n",
    "    \n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),ha=\"center\", va=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(diff, classes=['M', 'T', 'A', 'V'],\n",
    "                      title='')\n",
    "plt.savefig('/home/iyuge2/Project/MSA-ZH/asserts/Annotation-diff.pdf', dpi=600, pad_inches=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 生成结果分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = ['EF_LSTM', 'LF_DNN', 'LMF', 'MFN', 'MULT', 'TFN']\n",
    "df = pd.DataFrame(columns=['' for i in range(6)], index=method_names)\n",
    "working_dir = '/home/iyuge2/Project/MSA-ZH/results/msazh'\n",
    "methods = sorted(glob(os.path.join(working_dir, '*.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cur_method in enumerate(methods):\n",
    "    df_src = pd.read_csv(cur_method, index_col=0)\n",
    "    if cur_method.split('/')[-1] == 'stat.csv':\n",
    "        continue\n",
    "    if i == 0:\n",
    "        df.columns = list(df_src.index)\n",
    "    method_name = str.upper(cur_method.split('/')[-1].split('-')[0])\n",
    "    evals = []\n",
    "    for i in range(len(df_src)):\n",
    "        evals.append(df_src.iloc[i][-1])\n",
    "    df.loc[method_name] = evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(working_dir, 'stat.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- text(Bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_class = BertTokenizer\n",
    "model_class = BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory is fine\n",
    "pretrained_weights = '/home/sharing/disk3/pretrained_embedding/Chinese/bert/pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_special_tokens will add start and end token\n",
    "input_ids = torch.tensor([tokenizer.encode(\"我有一个苹果\", add_special_tokens=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids)[0]  # Models outputs are now tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/home/sharing/disk2/multimodal-sentiment-dataset/MSA-ZH/Processed/features/data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['feature_T'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mosi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/sharing/disk2/multimodal-sentiment-dataset/MOSI/labels/OpinionLevelSentiment.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pickle.load(open('/home/sharing/disk2/multimodal-sentiment-dataset/MOSI/Processed/seq_length_50/mosi_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['train'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = a['train']['vision']\n",
    "tt = a['train']['text']\n",
    "ta = a['train']['audio']\n",
    "tid = a['train']['id']\n",
    "tlabel = a['train']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/home/sharing/disk3/dataset/multimodal/msa-zh/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.dirname(input_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 从视频中提取帧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/home/sharing/disk3/dataset/multimodal/msa-zh/result/raw'\n",
    "output_dir = '/home/sharing/disk3/dataset/multimodal/msa-zh/result/Processed/video/Frame'\n",
    "video_pathes = sorted(glob(os.path.join(input_dir, '*/*.mp4')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_pathes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id, clip_id = video_pathes[0].split('/')[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_path in tqdm(video_pathes):\n",
    "    video_id, clip_id = video_path.split('/')[-2:]\n",
    "    clip_id = clip_id.split('.')[0]\n",
    "    cur_output_dir = os.path.join(output_dir, video_id, clip_id)\n",
    "    if not os.path.exists(cur_output_dir):\n",
    "        os.makedirs(cur_output_dir)\n",
    "    cmd = \"ffmpeg -i \" + video_path + \" -r 30 \" + cur_output_dir + \"/%04d.png\"\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_output_dir = os.path.join(output_dir, input_dir.split('/')[-1])\n",
    "if not os.path.exists(video_output_dir):\n",
    "    os.mkdir(video_output_dir)\n",
    "for cur_video in videos:\n",
    "    output_path = os.path.join(video_output_dir, os.path.basename(cur_video).split('_')[0])\n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "    cmd = \"ffmpeg -i \" + cur_video + \" -r 30 \" + output_path + \"/%04d.png\"\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 统计帧数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "videos = sorted(glob(os.path.join(output_dir, 'video_*')))\n",
    "for cur_video in videos:\n",
    "    video_clips = sorted(os.listdir(cur_video))\n",
    "    for cur_clip in video_clips:\n",
    "        xs.append(len(ys))\n",
    "        ys.append(len(glob(os.path.join(cur_video, cur_clip, '*.png'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 从帧中提取对齐后的人脸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "133 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = './Frames'\n",
    "output_dir = './AlignedFaces'\n",
    "videos = sorted(glob(os.path.join(input_dir, 'video_*')))\n",
    "mtcnn = MTCNN(image_size=224, margin=0)\n",
    "sx, sy = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cur_video in videos:\n",
    "    video_clips = sorted(os.listdir(cur_video))\n",
    "#     print(video_clips)\n",
    "    for cur_clip in tqdm(video_clips):\n",
    "        imgs = sorted(glob(os.path.join(cur_video, cur_clip, '*.png')))\n",
    "        for cur_img in imgs:\n",
    "            output_path = cur_img.replace('Frames', 'AlignedFaces')\n",
    "            cur_output_dir = os.path.dirname(output_path)\n",
    "            if not os.path.exists(cur_output_dir):\n",
    "                os.makedirs(cur_output_dir)\n",
    "            img = Image.open(cur_img)\n",
    "            mtcnn(img, save_path=output_path)\n",
    "        sx.append(len(sy))\n",
    "        sy.append(len(glob(os.path.join(cur_output_dir, '*.png'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sx, sy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MOSI && MOSEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as plk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(src_path, dst_dir, save_name):\n",
    "    # format raw features as our format (for MOSI, MOSEI)\n",
    "    with open(src_path, 'rb') as df:\n",
    "        data = plk.load(df)\n",
    "    train_len = len(data['train']['labels'])\n",
    "    valid_len = len(data['valid']['labels'])\n",
    "    test_len = len(data['test']['labels'])\n",
    "    print(train_len, valid_len, test_len)\n",
    "    \n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.makedirs(dst_dir)\n",
    "    \n",
    "    # format data\n",
    "    print('format data')\n",
    "    new_data = {}\n",
    "    for item in data['train'].keys():\n",
    "        cur = []\n",
    "        for mode in ['train', 'valid', 'test']:\n",
    "            cur.append(data[mode][item])\n",
    "        new_data[item] = np.concatenate(cur, axis = 0)\n",
    "    \n",
    "    # add the \"protocol\" param to support file larger than 4 GBs.\n",
    "    with open(os.path.join(dst_dir, save_name + '_data.pkl'), 'wb') as df:\n",
    "        plk.dump(new_data, df, protocol = 4)\n",
    "    \n",
    "    # get train/valid/test index\n",
    "    print('get train/valid/test index')\n",
    "    new_index = {}\n",
    "    new_index['train'] = np.array([i for i in range(train_len)])\n",
    "    new_index['valid'] = np.array([i for i in range(train_len, train_len+valid_len)])\n",
    "    new_index['test'] = np.array([i for i in range(train_len+valid_len, train_len+valid_len+test_len)])\n",
    "    \n",
    "    # save index\n",
    "    indexPath = os.path.join(dst_dir, save_name + '_index.pkl')\n",
    "    if not os.path.exists(indexPath):\n",
    "        with open(indexPath, 'wb') as df:\n",
    "            plk.dump(new_index, df, protocol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16265 1869 4643\n",
      "format data\n",
      "get train/valid/test index\n"
     ]
    }
   ],
   "source": [
    "src_path = '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/CMU-MOSEI/Processed/mosei_senti_data.pkl'\n",
    "dst_dir = '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/CMU-MOSEI/Processed/Format/Our'\n",
    "save_name = 'mosei_aligned'\n",
    "formatData(src_path, dst_dir, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the first 300 is the word vectors, the next 5 are acoustic and the rest is visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/CMU_MOSI'\n",
    "X_train = h5py.File(os.path.join(root_dir, 'Processed/seq_length_20/X_train.h5'), 'r')\n",
    "X_valid = h5py.File(os.path.join(root_dir, 'Processed/seq_length_20/X_valid.h5'), 'r')\n",
    "X_test = h5py.File(os.path.join(root_dir, 'Processed/seq_length_20/X_test.h5'), 'r')\n",
    "y_train = h5py.File(os.path.join(root_dir, 'Processed/seq_length_20/y_train.h5'), 'r')\n",
    "y_valid = h5py.File(os.path.join(root_dir, 'Processed/seq_length_20/y_valid.h5'), 'r')\n",
    "y_test = h5py.File(os.path.join(root_dir, 'Processed/seq_length_20/y_test.h5'), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train['data'])\n",
    "X_valid = np.array(X_valid['data'])\n",
    "X_test = np.array(X_test['data'])\n",
    "y_train = np.array(y_train['data'])\n",
    "y_valid = np.array(y_valid['data'])\n",
    "y_test = np.array(y_test['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {}\n",
    "new_data['text'] = np.concatenate([X_train[:,:,:300], X_valid[:,:,:300], X_test[:,:,:300]], axis=0)\n",
    "new_data['audio'] = np.concatenate([X_train[:,:,300:305], X_valid[:,:,300:305], X_test[:,:,300:305]], axis=0)\n",
    "new_data['vision'] = np.concatenate([X_train[:,:,305:], X_valid[:,:,305:], X_test[:,:,305:]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['labels'] = np.concatenate([y_train, y_valid, y_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CH-SIMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['feature_T', 'feature_A', 'feature_V', 'label_T', 'label_A', 'label_V', 'label_M'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('/home/sharing/disk3/dataset/multimodal-sentiment-dataset/CH-SIMS/Processed/features/data.npz')\n",
    "data = dict(data)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = '/home/sharing/disk3/dataset/multimodal-sentiment-dataset/CH-SIMS/metadata/sentiment'\n",
    "df_label_T = pd.read_csv(os.path.join(label_path, 'label_T.csv'))\n",
    "df_label_A = pd.read_csv(os.path.join(label_path, 'label_A.csv'))\n",
    "df_label_V = pd.read_csv(os.path.join(label_path, 'label_V.csv'))\n",
    "df_label_M = pd.read_csv(os.path.join(label_path, 'label_M.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_class = BertTokenizer\n",
    "model_class = BertModel\n",
    "# directory is fine\n",
    "# pretrained_weights = '/home/sharing/disk3/pretrained_embedding/Chinese/bert/pytorch'\n",
    "pretrained_weights = '/home/sharing/disk3/pretrained_embedding/bert/chinese_L-12_H-768_A-12'\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2281/2281 [00:01<00:00, 1219.24it/s]\n"
     ]
    }
   ],
   "source": [
    "text_len = data['feature_T'].shape[1]\n",
    "ids, rawText = [], []\n",
    "Input_ids = []\n",
    "Input_mask, segment_ids = [], []\n",
    "for i in tqdm(range(len(df_label_T))):\n",
    "    video_id, clip_id = df_label_T.loc[i, ['video_id', 'clip_id']]\n",
    "    clip_id = '%04d' % clip_id\n",
    "    \n",
    "    ids.append(video_id + '_' + clip_id)\n",
    "    text = df_label_T.loc[i, 'text']\n",
    "    rawText.append(text)\n",
    "    \n",
    "    if len(text) > text_len - 2:\n",
    "        text = text[:text_len-2]\n",
    "    \n",
    "    cur_input = torch.tensor(tokenizer.encode(text, add_special_tokens=True))\n",
    "    cur_input = list(cur_input.squeeze().numpy())\n",
    "    Input_ids.append(cur_input + [0]*(text_len - len(cur_input)))\n",
    "    Input_mask.append([1] * (len(cur_input)) + [0] * (text_len - len(cur_input)))\n",
    "    segment_ids.append([0]*text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_ids = np.array(Input_ids)\n",
    "Input_mask = np.array(Input_mask)\n",
    "segment_ids = np.array(segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sharing/disk3/dataset/multimodal-sentiment-dataset/CH-SIMS/metadata/index.pkl', 'rb') as tmp:\n",
    "    indexes = plk.load(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = indexes['train']\n",
    "valid_index = indexes['valid']\n",
    "test_index = indexes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(index):\n",
    "    results = {}\n",
    "    results['feature_T'] = data['feature_T'][index]\n",
    "    results['feature_A'] = data['feature_A'][index]\n",
    "    results['feature_V'] = data['feature_V'][index]\n",
    "    \n",
    "    results['label_T'] = data['label_T'][index]\n",
    "    results['label_A'] = data['label_A'][index]\n",
    "    results['label_V'] = data['label_V'][index]\n",
    "    results['label_M'] = data['label_M'][index]\n",
    "    \n",
    "    results['ids'] = [ids[i] for i in index]\n",
    "    results['raw_text'] = [rawText[i] for i in index]\n",
    "    \n",
    "    tmp_in_ids = np.expand_dims(Input_ids[index], 1)\n",
    "    tmp_in_mask = np.expand_dims(Input_mask[index], 1)\n",
    "    tmp_seg_ids = np.expand_dims(segment_ids[index], 1)\n",
    "    \n",
    "    results['text_bert'] = np.concatenate((tmp_in_ids, tmp_in_mask, tmp_seg_ids), axis=1) \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = {}\n",
    "save['train'] = splitData(train_index)\n",
    "save['valid'] = splitData(valid_index)\n",
    "save['test'] = splitData(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1368, 3, 39)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save['train']['text_bert'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sharing/disk3/dataset/multimodal-sentiment-dataset/ALL/sims/unaligned_37.pkl', 'wb') as df:\n",
    "    plk.dump(save, df, protocol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sharing/disk3/dataset/multimodal-sentiment-dataset/ALL/mosi/feature/aligned_50.pkl', 'rb') as ff:\n",
    "    alignedData = plk.load(ff)\n",
    "with open('/home/sharing/disk3/dataset/multimodal-sentiment-dataset/ALL/mosi/raw/aligned_50.pkl', 'rb') as ff:\n",
    "    rawAlignedData = plk.load(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vision', 'labels', 'text', 'audio', 'id'])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignedData['train'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['raw_text', 'audio', 'vision', 'labels', 'id', 'text'])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawAlignedData['train'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in ['train', 'valid', 'test']:\n",
    "    rawAlignedData[mode]['text_bert'] = rawAlignedData[mode]['text']\n",
    "    rawAlignedData[mode]['text'] = alignedData[mode]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['raw_text', 'audio', 'vision', 'labels', 'id', 'text', 'text_bert'])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawAlignedData['valid'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sharing/disk3/dataset/multimodal-sentiment-dataset/ALL/mosi/aligned_50.pkl', 'wb') as df:\n",
    "    plk.dump(rawAlignedData, df, protocol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sharing/disk3/dataset/multimodal-sentiment-dataset/ALL/sims/unaligned_39.pkl', 'rb') as lf:\n",
    "    data = plk.load(lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['feature_T', 'feature_A', 'feature_V', 'label_T', 'label_A', 'label_V', 'label_M', 'ids', 'raw_text', 'text_bert'])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['feature_T', 'feature_A', 'feature_V', 'label_T', 'label_A', 'label_V', 'label_M', 'ids', 'raw_text', 'text_bert'])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['valid'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['feature_T', 'feature_A', 'feature_V', 'label_T', 'label_A', 'label_V', 'label_M', 'ids', 'raw_text', 'text_bert'])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['test'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sharing/disk3/dataset/multimodal-sentiment-dataset/ALL/sims/unaligned_39.pkl', 'wb') as df:\n",
    "    plk.dump(data, df, protocol = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 补充序列长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sharing/disk3/dataset/multimodal-sentiment-dataset/ALL/mosei/unaligned_50.pkl', 'rb') as lf:\n",
    "    data = plk.load(lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sharing/disk3/dataset/multimodal-sentiment-dataset/ALL/mosi/unaligned_50.pkl', 'rb') as lf:\n",
    "    data = plk.load(lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['raw_text', 'audio', 'vision', 'labels', 'id', 'text', 'text_bert', 'audio_lengths', 'vision_lengths'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1284, 375, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['audio'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lengths(mode, feature_name):\n",
    "    fd = data[mode][feature_name]\n",
    "    max_len = fd.shape[1]\n",
    "    \n",
    "    c_sum = np.sum(fd, axis=-1)\n",
    "    new_features = []\n",
    "    lengths = []\n",
    "    for i in tqdm(range(fd.shape[0])):\n",
    "        null = True\n",
    "        zeros = np.zeros([fd.shape[1], fd.shape[2]])\n",
    "        for j in range(max_len):\n",
    "            if c_sum[i][j] != 0:\n",
    "                lengths.append(max_len - j)\n",
    "                tmp_feat = np.concatenate([fd[i,j:], zeros[:j]], axis = 0)\n",
    "                null = False\n",
    "                break\n",
    "        if null:\n",
    "            lengths.append(1)\n",
    "            new_features.append(fd[i])\n",
    "        else:\n",
    "            new_features.append(tmp_feat)\n",
    "    return lengths, np.array(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 686/686 [00:00<00:00, 102060.60it/s]\n"
     ]
    }
   ],
   "source": [
    "mode = 'test'\n",
    "ll, _ = get_lengths(mode, 'audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4659/4659 [00:00<00:00, 14063.92it/s]\n",
      "100%|██████████| 4659/4659 [00:00<00:00, 23270.28it/s]\n"
     ]
    }
   ],
   "source": [
    "mode = 'test'\n",
    "data[mode]['audio_lengths'], data[mode]['audio'] = get_lengths(mode, 'audio')\n",
    "data[mode]['vision_lengths'], data[mode]['vision'] = get_lengths(mode, 'vision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sharing/disk3/dataset/multimodal-sentiment-dataset/ALL/mosei/unaligned_50_new.pkl', 'wb') as df:\n",
    "    plk.dump(data, df, protocol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_counts(labels):\n",
    "#     ms = [-1.01, -0.7, -0.1, 0.1, 0.7, 1.01] # splits\n",
    "#     ms = [-3.5, -2.5, -1.5, -0.5, 0.5, 1.5, 2.5, 3.5]\n",
    "    ms = [-3.5, 0.0, 3.5]\n",
    "    counts = []\n",
    "    for i in range(len(ms)-1):\n",
    "        c_num = (labels >= ms[i]) & (labels < ms[i+1])\n",
    "        counts.append(c_num.sum())\n",
    "    return counts\n",
    "\n",
    "def draw(data, epochs=1):\n",
    "    c_data = data[epochs]\n",
    "    label_counts_M = label_counts(c_data['fusion'])\n",
    "    label_counts_T = label_counts(c_data['text'])\n",
    "    label_counts_A = label_counts(c_data['audio'])\n",
    "    label_counts_V = label_counts(c_data['vision'])\n",
    "    \n",
    "    x =np.arange(len(label_counts_M))\n",
    "    bar_width = 0.15\n",
    "    fc_M = [1/255,77/255,103/255]\n",
    "    fc_T = [96/255,143/255,159/255]\n",
    "    fc_A = [251/255,178/255,23/255]\n",
    "    fc_V = [237/255,222/255,139/255]\n",
    "    \n",
    "    plt.figure(figsize=(4, 4)) #  设置图大小\n",
    "    \n",
    "    plt.bar(x, label_counts_M, width=bar_width, label='M',fc = fc_M)\n",
    "    plt.bar(x+bar_width, label_counts_T, width=bar_width, label='T',fc = fc_T)\n",
    "    plt.bar(x+bar_width*2, label_counts_A, width=bar_width, label='A',fc = fc_A)\n",
    "    plt.bar(x+bar_width*3, label_counts_V, width=bar_width, label='V',fc = fc_V)\n",
    "    \n",
    "#     annotations = ['Negative','Weakly Negative','Neutral','Weakly Positive', 'Positive']\n",
    "    annotations = ['Negative', 'Positive']\n",
    "\n",
    "#     plt.legend(loc='best', fontsize=8) # 设置图例\n",
    "    plt.xticks(x+1.5*bar_width,annotations, rotation=0)#显示x坐标轴的标签,即tick_label,调整位置，使其落在两个直方图中间位置\n",
    "    plt.savefig('dataset-bar.pdf', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/iyuge2/Project/MSA-AAAI2021/results/FinalSave/lsmmsa-mosi.pkl', 'rb') as df:\n",
    "    data = plk.load(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "draw(data, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = data[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################\n",
      "0.8\n",
      "-0.61236525\n",
      "0.021002334\n",
      "0.38798374\n",
      "2WGyTLYerpo_43\n",
      "########################\n",
      "########################\n",
      "0.2\n",
      "-0.18476462\n",
      "0.18690544\n",
      "0.014432773\n",
      "VbQk4H8hgr0_40\n",
      "########################\n",
      "########################\n",
      "0.6\n",
      "-0.71565354\n",
      "-0.3044953\n",
      "0.8664003\n",
      "BI97DNYfe5I_28\n",
      "########################\n",
      "########################\n",
      "0.8\n",
      "-0.26670468\n",
      "-0.9691915\n",
      "-0.20726396\n",
      "OQvJTdtJ2H4_6\n",
      "########################\n",
      "########################\n",
      "0.8\n",
      "-0.68449354\n",
      "0.7882346\n",
      "0.11034965\n",
      "Njd1F0vZSm4_4\n",
      "########################\n",
      "########################\n",
      "0.4\n",
      "-0.66205025\n",
      "0.16210768\n",
      "0.38561234\n",
      "TvyZBvOMOTc_8\n",
      "########################\n",
      "########################\n",
      "1.25\n",
      "-0.8509356\n",
      "-0.99592495\n",
      "-0.46805984\n",
      "Vj1wYRQjB-o_6\n",
      "########################\n",
      "########################\n",
      "1.4\n",
      "-0.66339445\n",
      "-1.1928812\n",
      "-0.7927389\n",
      "G-xst2euQUc_20\n",
      "########################\n",
      "########################\n",
      "0.2\n",
      "-0.9382811\n",
      "0.81306154\n",
      "0.6729532\n",
      "PZ-lDQFboO8_10\n",
      "########################\n",
      "########################\n",
      "0.6\n",
      "-0.57875186\n",
      "1.1517175\n",
      "0.4747908\n",
      "Af8D0E4ZXaw_1\n",
      "########################\n",
      "########################\n",
      "0.4\n",
      "-0.7891041\n",
      "-0.37805116\n",
      "1.070795\n",
      "Nzq88NnDkEk_15\n",
      "########################\n",
      "########################\n",
      "1.0\n",
      "-0.94510674\n",
      "-0.50691456\n",
      "0.39440268\n",
      "VbQk4H8hgr0_30\n",
      "########################\n",
      "########################\n",
      "0.4\n",
      "-0.5508054\n",
      "0.2507463\n",
      "1.2008462\n",
      "VbQk4H8hgr0_15\n",
      "########################\n",
      "########################\n",
      "1.2\n",
      "-0.8688658\n",
      "-0.44669023\n",
      "0.27265993\n",
      "1DmNV9C1hbY_2\n",
      "########################\n",
      "########################\n",
      "0.6\n",
      "-0.4881416\n",
      "-0.43984228\n",
      "0.7970431\n",
      "BioHAh1qJAQ_9\n",
      "########################\n",
      "########################\n",
      "1.0\n",
      "-0.6956445\n",
      "-0.3160429\n",
      "-0.2574501\n",
      "BioHAh1qJAQ_26\n",
      "########################\n",
      "########################\n",
      "0.8\n",
      "-0.74180645\n",
      "-0.10507731\n",
      "-0.7302964\n",
      "03bSnISJMiM_10\n",
      "########################\n",
      "########################\n",
      "1.4\n",
      "-0.18201685\n",
      "-1.6244596\n",
      "-0.82162833\n",
      "5W7Z1C_fDaE_23\n",
      "########################\n",
      "########################\n",
      "0.2\n",
      "-0.9715594\n",
      "1.1092231\n",
      "0.7929619\n",
      "BI97DNYfe5I_1\n",
      "########################\n",
      "########################\n",
      "0.2\n",
      "-0.39545935\n",
      "0.84655124\n",
      "0.55220747\n",
      "7JsX8y1ysxY_34\n",
      "########################\n",
      "########################\n",
      "0.6\n",
      "-0.8738819\n",
      "-0.6213707\n",
      "0.27756518\n",
      "2iD-tVS8NPw_9\n",
      "########################\n",
      "########################\n",
      "0.6\n",
      "-0.5793174\n",
      "0.31072703\n",
      "1.1350882\n",
      "8d-gEyoeBzc_27\n",
      "########################\n",
      "########################\n",
      "0.6\n",
      "-0.56607616\n",
      "0.22373079\n",
      "-0.63927984\n",
      "73jzhE8R1TQ_1\n",
      "########################\n",
      "########################\n",
      "0.4\n",
      "-0.592893\n",
      "0.47480223\n",
      "0.683944\n",
      "BvYR0L6f2Ig_22\n",
      "########################\n",
      "########################\n",
      "1.0\n",
      "-0.89265037\n",
      "0.34083003\n",
      "0.1437463\n",
      "QN9ZIUWUXsY_18\n",
      "########################\n",
      "########################\n",
      "0.8\n",
      "-0.66766465\n",
      "0.41799295\n",
      "0.12807563\n",
      "VCslbP0mgZI_11\n",
      "########################\n",
      "########################\n",
      "1.2\n",
      "-0.56594086\n",
      "0.6453811\n",
      "-0.41802034\n",
      "POKffnXeBds_3\n",
      "########################\n",
      "########################\n",
      "0.5\n",
      "-0.8169137\n",
      "0.60824794\n",
      "0.7132849\n",
      "9qR7uwkblbs_8\n",
      "########################\n",
      "########################\n",
      "0.2\n",
      "-0.00413651\n",
      "0.39100724\n",
      "-0.050039254\n",
      "7JsX8y1ysxY_3\n",
      "########################\n",
      "########################\n",
      "1.2\n",
      "-0.9729484\n",
      "-0.5556277\n",
      "-0.37293103\n",
      "Sqr0AcuoNnk_13\n",
      "########################\n",
      "########################\n",
      "0.6\n",
      "-0.5287543\n",
      "0.3129601\n",
      "0.25121745\n",
      "Ci-AH39fi3Y_32\n",
      "########################\n",
      "########################\n",
      "1.2\n",
      "-0.66789955\n",
      "0.7018885\n",
      "0.7996395\n",
      "1DmNV9C1hbY_3\n",
      "########################\n",
      "########################\n",
      "1.4\n",
      "-0.53204685\n",
      "-1.4847192\n",
      "-0.43509147\n",
      "BI97DNYfe5I_20\n",
      "########################\n",
      "########################\n",
      "0.8\n",
      "-0.74102426\n",
      "0.51725847\n",
      "0.7706901\n",
      "Jkswaaud0hk_20\n",
      "########################\n",
      "########################\n",
      "1.0\n",
      "-0.8859808\n",
      "-1.0054952\n",
      "-0.4169532\n",
      "Jkswaaud0hk_1\n",
      "########################\n",
      "########################\n",
      "0.2\n",
      "-0.63046104\n",
      "0.03984209\n",
      "0.9749903\n",
      "QN9ZIUWUXsY_6\n",
      "########################\n",
      "########################\n",
      "1.6\n",
      "-1.0165871\n",
      "-0.6010313\n",
      "-0.62079376\n",
      "Bfr499ggo-0_22\n",
      "########################\n",
      "########################\n",
      "0.2\n",
      "-0.63173366\n",
      "1.2306123\n",
      "0.887841\n",
      "Af8D0E4ZXaw_14\n",
      "########################\n",
      "########################\n",
      "1.2\n",
      "-0.47763252\n",
      "0.22978309\n",
      "-0.26918593\n",
      "2WGyTLYerpo_50\n",
      "########################\n",
      "########################\n",
      "0.33333334\n",
      "-0.6832155\n",
      "-0.37432206\n",
      "0.9682528\n",
      "8qrpnFRGt2A_20\n",
      "########################\n",
      "########################\n",
      "0.8\n",
      "-0.7355935\n",
      "0.28715354\n",
      "0.21169117\n",
      "HEsqda8_d0Q_11\n",
      "########################\n",
      "########################\n",
      "1.4\n",
      "-0.53725874\n",
      "-0.37641615\n",
      "-0.20606157\n",
      "1DmNV9C1hbY_13\n",
      "########################\n",
      "########################\n",
      "0.4\n",
      "-0.7105267\n",
      "0.77558106\n",
      "0.86711484\n",
      "W8NXH0Djyww_7\n",
      "########################\n",
      "########################\n",
      "0.5\n",
      "-0.67530864\n",
      "0.40188903\n",
      "-0.13848498\n",
      "1iG0909rllw_27\n",
      "########################\n",
      "########################\n",
      "0.4\n",
      "-0.8231442\n",
      "0.5607748\n",
      "0.98309165\n",
      "HEsqda8_d0Q_32\n",
      "########################\n",
      "########################\n",
      "0.8\n",
      "-0.6104189\n",
      "-0.742129\n",
      "0.6710526\n",
      "2iD-tVS8NPw_1\n",
      "########################\n",
      "########################\n",
      "0.25\n",
      "-0.6125515\n",
      "0.96436065\n",
      "1.1949391\n",
      "8qrpnFRGt2A_7\n",
      "########################\n",
      "########################\n",
      "0.2\n",
      "-0.4187135\n",
      "-0.2826872\n",
      "0.43120238\n",
      "Bfr499ggo-0_18\n",
      "########################\n",
      "########################\n",
      "1.2\n",
      "-0.8566575\n",
      "-0.7394902\n",
      "0.7257205\n",
      "HEsqda8_d0Q_4\n",
      "########################\n",
      "########################\n",
      "0.6\n",
      "-0.5937815\n",
      "-0.48592234\n",
      "0.36531553\n",
      "1iG0909rllw_4\n",
      "########################\n",
      "########################\n",
      "0.8\n",
      "-0.7734077\n",
      "0.82420826\n",
      "0.08294331\n",
      "8d-gEyoeBzc_26\n",
      "########################\n"
     ]
    }
   ],
   "source": [
    "s_id = 0\n",
    "select = 0\n",
    "for s_id in range(len(dd['fusion'])):\n",
    "    if dd['fusion'][s_id] > 0 and dd['text'][s_id] < 0:\n",
    "        print(\"########################\")\n",
    "        print(dd['fusion'][s_id])\n",
    "        print(dd['text'][s_id])\n",
    "        print(dd['audio'][s_id])\n",
    "        print(dd['vision'][s_id])\n",
    "        print(dd['ids'][s_id])\n",
    "        print(\"########################\")\n",
    "        select += 1\n",
    "    if select > 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
